{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有节点划分社区，并将同一社区的连边权值加大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vials: Visualizing Alternative Splicing of Genes\n",
      "('The Connected Scatterplot for Presenting Paired Time Series', 'A Visual Analytics Approach to Dynamic Network Exploration')\n",
      "11585\n",
      "28435\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取 JSON 文件\n",
    "with open(\"../output_data/sourceJson_All.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsonData = json.load(f)  # 解析 JSON 文件\n",
    "\n",
    "nodes=[node[\"id\"] for node in jsonData[\"nodes\"]]\n",
    "links=[(link[\"source\"],link[\"target\"]) for link in jsonData[\"links\"]]\n",
    "\n",
    "print(nodes[-1])\n",
    "print(links[-1])\n",
    "print(len(nodes))\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11585\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加节点\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "# 添加边\n",
    "G.add_edges_from(links)\n",
    "\n",
    "print(len(G.nodes()))\n",
    "\n",
    "# 运行 Louvain 算法\n",
    "communities = louvain_communities(G)\n",
    "print(len(communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# 将社区划分到最精确\n",
    "res=1   # 分辨率默认为1\n",
    "commNum=len(communities)\n",
    "preCommNum=-1\n",
    "print(commNum)\n",
    "while preCommNum<commNum:\n",
    "    preCommNum=commNum\n",
    "    res=res/2\n",
    "    communities=louvain_communities(G,resolution=res)\n",
    "    commNum=len(communities)\n",
    "print(commNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11585\n",
      "11585\n"
     ]
    }
   ],
   "source": [
    "nodeNum=0\n",
    "for comm in communities:\n",
    "    nodeNum+=len(comm)\n",
    "print(nodeNum)\n",
    "print(len(nodes))\n",
    "# 验证社区内节点没有变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后社区数: 10\n"
     ]
    }
   ],
   "source": [
    "pop_communites=[]\n",
    "# 合并小社区\n",
    "def merge_small_communities(G, communities, max_communities):\n",
    "    \"\"\"合并较小的社区，直到满足最大社区数量要求\"\"\"\n",
    "    while len(communities) > max_communities:\n",
    "        # 计算每个社区的大小 从小到大\n",
    "        communities = sorted(communities, key=len)\n",
    "        smallest = communities.pop(0)  # 弹出最小的社区\n",
    "        # 找到它的邻居社区\n",
    "        neighbor_counts = {}\n",
    "        # 取出最小社区的节点——找到该节点直连节点\n",
    "        # 找到直连节点所在社区号，计算为最小社区到该社区一次\n",
    "        for node in smallest:\n",
    "            for neighbor in G.neighbors(node):\n",
    "                for idx, comm in enumerate(communities):\n",
    "                    if neighbor in comm:\n",
    "                        neighbor_counts[idx] = neighbor_counts.get(idx, 0) + 1\n",
    "        # 合并到最近的邻居社区\n",
    "        if neighbor_counts:\n",
    "            # 返回最大的键\n",
    "            best_match = max(neighbor_counts, key=neighbor_counts.get)\n",
    "            communities[best_match] = communities[best_match].union(smallest)\n",
    "        else:\n",
    "            # 保留舍弃的小社区\n",
    "            pop_communites.append(smallest)\n",
    "\n",
    "\n",
    "    return communities\n",
    "\n",
    "\n",
    "max_communities = 10  # 期望的最大社区数\n",
    "merged_communities = merge_small_communities(G, communities, max_communities)\n",
    "print(f\"合并后社区数: {len(merged_communities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "268\n",
      "362\n",
      "408\n",
      "646\n",
      "912\n",
      "1020\n",
      "1042\n",
      "2303\n",
      "2201\n",
      "2221\n",
      "11585\n"
     ]
    }
   ],
   "source": [
    "# 验证合并后节点数量没变\n",
    "count=0\n",
    "for comm in pop_communites:\n",
    "    count += len(comm)\n",
    "print(len(pop_communites))\n",
    "for comm in merged_communities:\n",
    "    count+=len(comm)\n",
    "    print(len(comm))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为所有节点编cluster号\n",
    "node_cluster_dc={}\n",
    "for idx,comm in enumerate(merged_communities):\n",
    "    for node in comm:\n",
    "        node_cluster_dc[node]=idx+1\n",
    "for comm in pop_communites:\n",
    "    for node in comm:\n",
    "        node_cluster_dc[node]=0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11585\n"
     ]
    }
   ],
   "source": [
    "# 验证所有节点都已编号\n",
    "print(len(node_cluster_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11585\n",
      "28435\n",
      "2989\n",
      "13567\n",
      "{'id': 'Vials: Visualizing Alternative Splicing of Genes', 'group': 1, 'doi': '10.1109/TVCG.2015.2467911', 'ab': 'Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.', 'keywords': 'Biology visualization,protein isoforms,mRNA-seq,directed acyclic   graphs,multivariate networks', 'year': '2016', 'auInst': 'Strobelt, Hendrik-Harvard Univ;Botros, Joseph-Harvard Univ;Pfister, Hanspeter-Harvard Univ;Lex, Alexander-Harvard Univ;Alsallakh, Bilal-Vienna Univ Technol;Peterson, Brant-Novartis Inst BioMed Res;Borowsky, Mark-Novartis Inst BioMed Res;Lex, Alexander-Univ Utah', 'cluster': 10}\n",
      "{'id': 'Vials: Visualizing Alternative Splicing of Genes', 'group': 1, 'doi': '10.1109/TVCG.2015.2467911', 'ab': 'Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.', 'keywords': 'Biology visualization,protein isoforms,mRNA-seq,directed acyclic   graphs,multivariate networks', 'year': '2016', 'auInst': 'Strobelt, Hendrik-Harvard Univ;Botros, Joseph-Harvard Univ;Pfister, Hanspeter-Harvard Univ;Lex, Alexander-Harvard Univ;Alsallakh, Bilal-Vienna Univ Technol;Peterson, Brant-Novartis Inst BioMed Res;Borowsky, Mark-Novartis Inst BioMed Res;Lex, Alexander-Univ Utah', 'cluster': 10}\n",
      "{'source': 'The Connected Scatterplot for Presenting Paired Time Series', 'target': 'A Visual Analytics Approach to Dynamic Network Exploration', 'value': 1}\n",
      "{'source': 'The Connected Scatterplot for Presenting Paired Time Series', 'target': 'A Visual Analytics Approach to Dynamic Network Exploration', 'value': 1}\n"
     ]
    }
   ],
   "source": [
    "# 为json数据添加cluster和权值改变\n",
    "jsonNodes=jsonData[\"nodes\"]\n",
    "jsonLinks=jsonData[\"links\"]\n",
    "print(len(jsonNodes))\n",
    "print(len(jsonLinks))\n",
    "\n",
    "with open(\"../output_data/sourceJson_Draw.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsonData_Draw = json.load(f)  # 解析 JSON 文件\n",
    "jsonNodes_Draw = jsonData_Draw[\"nodes\"]\n",
    "jsonLinks_Draw = jsonData_Draw[\"links\"]\n",
    "print(len(jsonNodes_Draw))\n",
    "print(len(jsonLinks_Draw))\n",
    "\n",
    "\n",
    "def updateNodes(nodes):\n",
    "    idx=0\n",
    "    for idx in range(len(nodes)):\n",
    "        jnode=nodes[idx]\n",
    "        nodes[idx][\"cluster\"] = node_cluster_dc[jnode[\"id\"]]\n",
    "    return nodes\n",
    "\n",
    "def updateLinks(links):\n",
    "    idx=0\n",
    "    for idx in range(len(links)):\n",
    "        jlink=links[idx]\n",
    "        i=node_cluster_dc[jlink[\"source\"]]\n",
    "        j=node_cluster_dc[jlink[\"target\"]]\n",
    "        if i==j:\n",
    "            links[idx][\"value\"]=10\n",
    "    return links\n",
    "\n",
    "updateNodes(jsonNodes)\n",
    "updateNodes(jsonNodes_Draw)\n",
    "updateLinks(jsonLinks)\n",
    "updateLinks(jsonLinks_Draw)\n",
    "\n",
    "print(jsonNodes[-1])\n",
    "print(jsonNodes_Draw[-1])\n",
    "print(jsonLinks[-1])\n",
    "print(jsonLinks_Draw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出为 JSON 文件\n",
    "jsonData[\"nodes\"] = jsonNodes\n",
    "jsonData[\"links\"] = jsonLinks\n",
    "jsonData_Draw[\"nodes\"]=jsonNodes_Draw\n",
    "jsonData_Draw[\"links\"] = jsonLinks_Draw\n",
    "\n",
    "with open(\"../output_data/jsonCluster_Draw2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(jsonData_Draw, f, indent=4, ensure_ascii=False)\n",
    "with open(\"../output_data/jsonCluster_All2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(jsonData, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2989\n",
      "13567\n",
      "11585\n",
      "28435\n"
     ]
    }
   ],
   "source": [
    "# 验证输出\n",
    "with open(\"../output_data/jsonCluster_Draw2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsonData = json.load(f)  \n",
    "print(len(jsonData[\"nodes\"]))\n",
    "print(len(jsonData[\"links\"]))\n",
    "with open(\"../output_data/jsonCluster_All2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jsonData = json.load(f)  \n",
    "print(len(jsonData[\"nodes\"]))\n",
    "print(len(jsonData[\"links\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
